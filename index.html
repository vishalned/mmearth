<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning">
  <meta property="og:title" content="MMEarth"/>
  <!-- <meta property="og:description" content="Large scale multi-modal remote sensing data"/> -->
  <meta property="og:url" content="https://vishalned.github.io/mmearth"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/banner2.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> 


  <meta name="twitter:title" content="MMEarth">
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/banner2.jpg">
  <!-- <meta name="twitter:card" content="MMEarth"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="representation learning,self-supervised learning,multi-modal, multi-task, masked autoencoder, Earth observation, remote sensing, satellite images, Sentinel-2">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MMEarth</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial Representation Learning</h1>

            <div class="centered">
              <div class="author-row">
                  <div class="col-6 text-center">
                    <a href="https://vishalned.github.io"  target="_blank"><img src="static/images/authors/vishal.jpg" alt="Vishal Nedungadi" class="">
                      <p>Vishal Nedungadi</p></a>
                  </div>
                  <div class="col-6 text-center">
                    <a href="https://scholar.google.de/citations?hl=en&user=lwSTZGgAAAAJ&view_op=list_works&sortby=pubdate"  target="_blank"><img src="static/images/authors/ankit.jpg" alt="Ankit Kariryaa" class="">
                      <p>Ankit Kariryaa</p></a> 
                  </div>
                  <div class="col-6 text-center">
                    <a href="https://scholar.google.de/citations?hl=en&user=k9EWJmcAAAAJ&view_op=list_works"  target="_blank"><img src="static/images/authors/stefan.jpg" alt="Stefan Oehmcke" class="">
                      <p>Stefan Oehmcke</p></a>
                  </div>
                  <div class="col-6 text-center">
                    <a href="https://sergebelongie.github.io/"  target="_blank"><img src="static/images/authors/serge.jpg" alt="Serge Belongie" class="">
                      <p>Serge Belongie</p></a>
                  </div>
                  <div class="col-6 text-center">
                    <a href="https://christian-igel.github.io/"  target="_blank"><img src="static/images/authors/christian.jpg" alt="Christian Igel" class="">
                      <p>Christian Igel</p></a>
                  </div>
                  <div class="col-6 text-center">
                    <a href="https://langnico.github.io/"  target="_blank"><img src="static/images/authors/nico.jpg" alt="Nico Lang" class="">
                      <p>Nico Lang</p></a>
                  </div>
                  
              </div>

                  <div class="is-size-5 publication-authors">
                    <a href="https://di.ku.dk/english/" style="color:#3273dc;"
                    <span class="author-block">University of Copenhagen<br>
                      <!-- Conferance name and year -->
                    </span>
                  </a>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/vishalned/MMEarth-data" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code - Data</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/vishalned/MMEarth-train" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code - Model</span>
                </a>
              </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The volume of unlabelled Earth observation (EO) data is huge, but many important applications lack labelled training data. However, EO data offers the unique opportunity to pair data from different modalities and sensors automatically based on geographic location and time, at virtually no human labor cost. We seize this opportunity to create a diverse multi-modal pretraining dataset at global scale. Using this new corpus of 1.2 million locations, we propose a Multi-Pretext Masked Autoencoder (MP-MAE) approach to learn general-purpose representations for optical satellite images. Our approach builds on the ConvNeXt V2 architecture, a fully convolutional masked autoencoder (MAE). Drawing upon a suite of multi-modal pretext tasks, we demonstrate that our MP-MAE approach outperforms both MAEs pretrained on ImageNet and MAEs pretrained on domain-specific satellite images. This is shown on several downstream tasks including image classification and semantic segmentation. We find that multi-modal pretraining notably improves the linear probing performance, e.g. 4pp on BigEarthNet and 16pp on So2Sat, compared to pretraining on optical satellite images only. We show that this also leads to better label and parameter efficiency which are crucial aspects in global scale applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">MMEarth Dataset</h2>
        <div class="content has-text-justified">
          <!-- some bullet points -->
          <ul>
            <li>MMEarth covers data from 1.2 million locations sampled globally, making the optical image count similar to ImageNet-1K. At each
              location, data from 12 geo-aligned modalities were collected and grouped into pixel-level and image-level modalities.
            </li>
            <li>MMEarth was sampled uniformly across 14 biomes, as per the <a href="https://academic.oup.com/bioscience/article/67/6/534/3102935?login=false" style="color:#3273dc;" target="_blank">Resolve Ecoregions</a> (e.g., Mangroves, Temperate Conifer Forests, Tundra, etc.). 
              To increase diversity, we considered data from the four years 2017–2020. 
              Furthermore, we ensured that time-critical modalities were collected around the Sentinel-2 observation date, which serves as the reference. 
            </li>
            <li>The six pixel-level modalities represent raster data of size 128 × 128 pixels which capture 1.28 km × 1.28 km on the ground 
              (e.g., Sentinel-2, Sentinel-1, Aster DEM, Dynamic World, and ESA World Cover). The remaining six image-level modalities represent scalar values for each location 
              (e.g., Biome, Ecoregion, ERA5 temperature, ERA5 precipitation, Geolocation, and Sentinel-2 observation date). 
            </li>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">MMEarth Model</h2>
        <div class="content has-text-justified">
          <!-- adding an image -->

          <!-- some bullet points -->
          <ul>
            <li>Our model, the Multi-Pretext Masked Autoencoder (MP-MAE), builds on the promising results of masked image modelling with the ConvNeXt V2 architecture.
              ConvNeXt V2 is a fully convolutional masked autoencoder (MAE) that uses sparse convolutions to predict the masked pixels of an image.
            </li>
            <li>Our MP-MAE model extends ConvNeXt V2 by adding a task-specific head for each pretext task. The general-purpose representation is learned by combining the losses of all pretext tasks. 
              For combining the losses, we use the uncertainty-weighted loss proposed by <a href="https://arxiv.org/abs/1705.07115" style="color:#3273dc;" target="_blank">Kendall et al. (2020)</a>.

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero">
  <figure class="model-image">
    <img src="static/images/model2.jpg" alt="MMEarth Model" >
  </figure>
  <!-- title -->
  <!-- <h2 class="title is-3 has-text-centered">MMEarth Model</h2> -->
</section>


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- create a title that is centered -->
      <h2 class="title is-3 has-text-centered">MMEarth examples</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel/img1.jpg" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          First image description.
        </h2> -->
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel/img2.jpg" alt="MY ALT TEXT"/>
        <!-- <h2 cs -->
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel/img3.jpg" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
         Third image description.
       </h2> -->
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel/img4.jpg" alt="MY ALT TEXT"/>
      <!-- <h2 class="subtitle has-text-centered">
       Fourth image description.
     </h2> -->
   </div>
     <!-- <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="static/images/carousel4.pdf" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2> -->
    <!-- </div> -->
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
